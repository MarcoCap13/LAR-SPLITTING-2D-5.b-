<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Studio Definitivo · LARSplitting2D.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">LARSplitting2D.jl</span></div><form class="docs-search" action="search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="index.html">Home</a></li><li><span class="tocitem">Documentazione</span><ul><li><a class="tocitem" href="relazione_preliminare.html">Studio Preliminare</a></li><li><a class="tocitem" href="relazione_esecutiva.html">Studio Esecutivo</a></li><li class="is-active"><a class="tocitem" href="relazione_definitiva.html">Studio Definitivo</a><ul class="internal"><li><a class="tocitem" href="#Obiettivi:"><span>Obiettivi:</span></a></li><li class="toplevel"><a class="tocitem" href="#RELAZIONE-DEL-PROGETTO"><span>RELAZIONE DEL PROGETTO</span></a></li><li><a class="tocitem" href="#Analisi-introduttiva"><span>Analisi introduttiva</span></a></li><li><a class="tocitem" href="#Metodi-di-parallelizzione-usati"><span>Metodi di parallelizzione usati</span></a></li><li><a class="tocitem" href="#Studio-delle-funzioni-ottimizzate"><span>Studio delle funzioni ottimizzate</span></a></li><li><a class="tocitem" href="#Funzionamento-dello-splitting"><span>Funzionamento dello splitting</span></a></li><li><a class="tocitem" href="#Esempio-dello-splitting"><span>Esempio dello splitting</span></a></li><li><a class="tocitem" href="#Funzioni-aggiuntive-create"><span>Funzioni aggiuntive create</span></a></li><li><a class="tocitem" href="#Test-delle-funzioni-principali-e-aggiuntive"><span>Test delle funzioni principali e aggiuntive</span></a></li><li><a class="tocitem" href="#Considerazioni-finali-sulla-parallelizzazione"><span>Considerazioni finali sulla parallelizzazione</span></a></li><li><a class="tocitem" href="#Grafo-delle-dipendenze-aggiornato"><span>Grafo delle dipendenze aggiornato</span></a></li></ul></li></ul></li><li><a class="tocitem" href="docs2d.html">Docstring</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Documentazione</a></li><li class="is-active"><a href="relazione_definitiva.html">Studio Definitivo</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="relazione_definitiva.html">Studio Definitivo</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/MarcoCap13/LAR-SPLITTING-2D-5.b-/blob/master/docs/src/relazione_definitiva.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><p>% Studio Definitivo Progetto LAR Splitting 2D – CPD22 % Gruppo: 5.b – Caponi Marco 508773, Ceneda Gianluca 488257 % \today</p><p>Prime analisi, test e possibili ottimizzazioni sul progetto LAR SPLITTING 2D con l’utilizzo della seguente repository:</p><ul><li><p>Main repository: https://github.com/MarcoCap13/LAR-SPLITTING-2D-5.b-</p><ul><li>https://github.com/cvdlab/LinearAlgebraicRepresentation.jl/blob/master/src/refactoring.jl</li></ul></li></ul><p>\tableofcontents</p><h2 id="Obiettivi:"><a class="docs-heading-anchor" href="#Obiettivi:">Obiettivi:</a><a id="Obiettivi:-1"></a><a class="docs-heading-anchor-permalink" href="#Obiettivi:" title="Permalink"></a></h2><ul><li>Studio del progetto <strong>LAR SPLITTING 2D</strong> e di tutte le funzioni e strutture dati utilizzate.</li><li>Descrizione di ogni task individuata, tipo e significato di ogni parametro ed eventuale valore di ritorno.</li><li>Suddivisione delle tipologie di funzioni e creazione di grafi delle dipendenze.</li><li>Individuare eventuali problemi riscontrati durante lo studio preliminare del codice.</li></ul><h1 id="RELAZIONE-DEL-PROGETTO"><a class="docs-heading-anchor" href="#RELAZIONE-DEL-PROGETTO">RELAZIONE DEL PROGETTO</a><a id="RELAZIONE-DEL-PROGETTO-1"></a><a class="docs-heading-anchor-permalink" href="#RELAZIONE-DEL-PROGETTO" title="Permalink"></a></h1><h2 id="Analisi-introduttiva"><a class="docs-heading-anchor" href="#Analisi-introduttiva">Analisi introduttiva</a><a id="Analisi-introduttiva-1"></a><a class="docs-heading-anchor-permalink" href="#Analisi-introduttiva" title="Permalink"></a></h2><p>Lo scopo del nostro progetto è stato quello di studiare e dove possibile migliorare attraverso metodi di parallelizzazione le prestazioni dei metodi e delle funzioni riguardante quest&#39;ultimo. Per far ciò ci siamo mossi creando nuove funzioni per alleggerire il codice, effettuando refactoring e applicando delle macro per poter gestire il tutto.</p><p>Per vedere le differenze di prestazioni tra una versione e un&#39;altra abbiamo usato due computer con caratteristiche hardware diverse e per alcune funzioni abbiamo utilizzato la workstation <strong>DGX-1</strong> messa a disposizione dal dipartimento di  <em>matematica e fisica di roma tre</em>. le differenze notate tra il computer meno performante e quello più performante sono state notevoli. Per quanto riguarda la parte precedente del codice, è presente una descrizione accurata dei vari dati acquisiti attraverso i nostri calcolatori e descritti nella relazione precedente, visitabile all&#39;indirizzo qui di seguito: \newline https://github.com/MarcoCap13/LAR-SPLITTING-2D-5.b-/blob/main/relazioni/relazione02.md</p><h2 id="Metodi-di-parallelizzione-usati"><a class="docs-heading-anchor" href="#Metodi-di-parallelizzione-usati">Metodi di parallelizzione usati</a><a id="Metodi-di-parallelizzione-usati-1"></a><a class="docs-heading-anchor-permalink" href="#Metodi-di-parallelizzione-usati" title="Permalink"></a></h2><p>Abbiamo continuato il nostro studio sulle <em>macro</em> per poter parallelizzare e migliorare la velocità computazionale delle varie funzioni. Nello specifico ci siamo soffermati questa volta sullo studio delle seguenti macro:</p><ul><li><p><strong>@views</strong>: con views si possono creare delle viste degli array che ci permettono di accedere ai valori di quest&#39;ultimo senza effettuare <em>nessuna copia</em></p></li><li><p><strong>@btime</strong>: questa macro svolge lo stesso lavoro di <em>@benchmark</em> ma restituisce un output </p></li></ul><p>meno complesso e più intuitivo, stampando a schermo le velocità di calcolo delle funzioni</p><ul><li><p><strong>@benchmark</strong>: Ci permette di valutare i parametri della funzione in maniera separata; Richiama la funzione più volte per creare un campione dei tempi di esecuzioni restituendo i tempi minimi, massimi e medi.</p></li><li><p><strong>@code_warntype</strong>: ci consente di visualizzare i tipi dedotti dal compilatore, identificando così tutte le instabilità di tipo nel codice preso in esame.</p></li></ul><p>Per quanto riguarda l&#39;ottimizzazione e la parallelizzazione delle funzioni, sono state impiegate le seguenti macro:</p><ul><li><p><strong>@threads</strong>: l&#39;utilizzo di questa macro è fondamentale per indicare a <em>Julia</em>  la presenza di <strong>loop</strong> che identificano <em>regioni multi-thread</em>.</p></li><li><p><strong>@spawn</strong>: identifica uno degli stumenti cardini di <em>Julia</em> per l&#39;assegnazioni dei vari compiti per le task. </p></li><li><p><strong>@async</strong>: questa macro crea e pianifica le attività per tutto il codice all&#39;inteno della sua attività. E&#39; similare alla macro <em>@spawn</em> con la differenza che runna le task solo a livello locale senza aspettare che il task termini.</p></li><li><p><strong>@sync</strong> il suon funzionamento è l&#39;opposto del precedente; Aspetta che tutti i task convolti nella parallelizzazione siano completati prima di poter proseguire a livello computazionale.</p></li></ul><h2 id="Studio-delle-funzioni-ottimizzate"><a class="docs-heading-anchor" href="#Studio-delle-funzioni-ottimizzate">Studio delle funzioni ottimizzate</a><a id="Studio-delle-funzioni-ottimizzate-1"></a><a class="docs-heading-anchor-permalink" href="#Studio-delle-funzioni-ottimizzate" title="Permalink"></a></h2><p>Per vedere nel dettaglio i nuovi dati ed i benchmark riporto il link diretto: </p><ul><li>https://github.com/MarcoCap13/LAR-SPLITTING-2D-5.b-/tree/main/docs/benchmark</li></ul><p>Lo studio preliminare del progetto è iniziato dalla comprensione del codice per capire come funzionasse lo <em>splitting 2D</em> per poi essere in grado di manipolare le strutture ad esso associate. Dopo di che si è passati allo studio delle funzioni più importanti come <em>spaceindex</em> e <em>pointInPolygonClassification</em> attraverso varie simulazioni delle stesse evidenziando così un&#39;instabilità di tipo su alcune sue variabili grazie all&#39;uso della macro <em>@code</em>warntype_ citata poco fa, oltre ad una velocita di esecuzione non proprio ottimale. Per risolvere questi problemi, si sono dovute studiare tutte le singole sotto-funzioni in particolare quelle che sollevavano l&#39;<strong>instabilità</strong> sul tipo:</p><ol><li><strong>spaceIndex</strong>: attraverso lo strumento <em>@code</em>warntype<em>, è emersa un&#39;instabilità in alcune variabili e non dell&#39;intero metodo. Nel particolare sono _type unstable</em>: bboxes, xboxdict, yboxdict, zboxdict, xcovers, ycovers, zcovers ed infine covers.</li></ol><p>Parallelizzando il codice e creando un funzione di supporto denominata <em>removeIntersection</em> per poter alleggerire il codice stesso, abbiamo raggiunto i seguenti risultati con un notevole miglioramento.     * Tipo: instabile     * Velocità di calcolo:          * iniziale: 116 <span>$\mu$</span>s          * modificata (con workstation DGX-1): 74.8 <span>$\mu$</span>s</p><ol><li><strong>boundingBox</strong>: attraverso l&#39;utilizzo della funzione denominata <em>@code</em>warntype<em>, è risultata un&#39;instabilità in questo metodo. L&#39;instabilità è dovuta unicamente alla funzione _mapslices</em>.</li></ol><p>Per ovviare a tale problematica abbiamo richiamato la funzione <em>hcat</em> che concatena due array lungo due dimensioni rendendo boundingbox <em>type stable</em> aumentando notevolmente le prestazioni. (per verificarlo abbiamo richiamato <em>@benchmark</em> e comparato i risultati)     * Tipo: instabile     * Velocità di calcolo:          * iniziale:  9.38 <span>$\mu$</span>s          * modificata (con workstation DGX-1): 8.21 <span>$\mu$</span>s</p><p>Altre sotto-funzioni <strong>type stable</strong> invece sono state studiate per comprendere il funzionamento del codice e analizzare i tempi di esecuzione:</p><ol><li><strong>boxcovering</strong>: boxcovering è type stable ma la variabile covers è un array di Any. Si procede tipizzando covers e dividendo la funzione in microtask.</li></ol><p>Per parallelizzare questa funzione abbiamo utilizzato la funzione <em>@Thread</em> e aggiunto due funzioni di supporto che illustreremo in seguito:  <em>createIntervalTree</em> e <em>addIntersection</em>.</p><pre><code class="language-none">* Tipo: stabile
* Velocità di calcolo: 
    * iniziale:   8.936 $\mu$s 
    * modificata (con workstation DGX-1): 4.46 $\mu$s</code></pre><ol><li><strong>coordintervals</strong>:Attraverso la macro <em>@code</em>warntype_ è stata individuata la stabilità di quest&#39;ultima.</li></ol><p>La funzione è risultata molto semplice e qualsiasi intervento svolto, non ha portato a grossi miglioramenti. Abbiamo utilizzato la macro <em>@inbounds</em> ma non ha portato a notevoli stravolgimenti.     * Tipo: stabile     * Velocità di calcolo:          * iniziale:   958.143 ns         * modificata: 1.029 <span>$\mu$</span>s  </p><ol><li><strong>fragmentlines</strong>:</li></ol><p>Abbiamo convertito alcune list comprehension in cicli del tipo for i=1:n .. in modo da poter utilizzare la macro <em>@inbounds</em> per disabilitare il boundchecking del compilatore.  L&#39;inserimento esplicito della macro simd non ha comportato alcun beneficio, infatti come si apprende dal sito ufficiale Julia: <em>&quot;Note that in many cases, Julia can automatically vectorize code without the @simd macro&quot;</em>.  Per quanto riguarda la macro <em>@inbounds</em>,invece, ha ridotto leggermente il numero di allocazioni in memoria.  Nel complesso non sono stati rilevati miglioramenti riguardo le prestazioni della versione iniziale e modificata.  Utilizzando la workstation <em>DGX-1</em> non abbiamo riscontrato migliorameti importanti.     * Tipo: stabile     * Velocità di calcolo:          * iniziale:   196.813 <span>$\mu$</span>s         * modificata: 197.939 <span>$\mu$</span>s </p><ol><li><strong>linefragment</strong>:</li></ol><p>Per quanto riguarda quest&#39;ultima funzione, sono stati riscontrati notevoli miglioramenti a livello di prestazioni utilizzando la macro <em>@threads</em>     * Tipo: stabile     * Velocità di calcolo:          * iniziale:   66.414 <span>$\mu$</span>s         * modificata: 33.001 <span>$\mu$</span>s </p><ol><li><strong>congruence</strong>:funzione che prende in ingresso un modello di Lar, restituendo una funzione di base denominata hcat che concatena due array lungo due dimensioni. Le macro utilizzate sono <em>@threads</em> e <em>@inbounds</em>. Si nota un certo miglioramento se utilizziamo dei <em>filter</em> per i dati di EV<ul><li>Tipo: stabile</li><li>Velocità di calcolo: <ul><li>iniziale:   36.8 <span>$\mu$</span>s</li><li>modificata (workstation DGX-1): 19.6 <span>$\mu$</span>s </li></ul></li></ul></li></ol><ol><li><strong>pointInPolygonClassification</strong>: funzione di notevole importanza nel nostro progetto. In questo caso abbiamo scomposto i vari else/if in tante <em>mono-task</em> per poter alleggerire il codice.</li></ol><p>Attraverso l&#39;utilizzo della macro <em>@async</em> abbiamo riscontrato un leggero  miglioramento rispetto alla funzione iniziale. </p><ul><li>Tipo: stabile<ul><li>Velocità di calcolo: <ul><li>iniziale:   82.6 <span>$\mu$</span>s</li><li>modificata: 81.1 <span>$\mu$</span>s </li></ul></li></ul></li></ul><h2 id="Funzionamento-dello-splitting"><a class="docs-heading-anchor" href="#Funzionamento-dello-splitting">Funzionamento dello splitting</a><a id="Funzionamento-dello-splitting-1"></a><a class="docs-heading-anchor-permalink" href="#Funzionamento-dello-splitting" title="Permalink"></a></h2><p>Nella figura sottostante vedremo come lavora <em>pointInPolygon</em> e il funzionamento dello splitting, denotando tutti quei segmenti che intersecano le facce del poligono preso in esame nel piano z=0. Nello specifico nel punto (a) vediamo i singoli segmenti (o linee) che intersecano il poligono; Nel sezione (b) vengono illustrati tutti quei punti che sono situati esternamente, internamente o sul bordo della faccia del poligono e nel punto (c) vengono cancellati tutti quei segmenti che vanno verso l&#39;esterno della faccia del poligono mentre per finire vediamo nel punto (d) il risultato finale dello <em>splitting</em>.</p><p>\newpage</p><p><img src="https://github.com/MarcoCap13/LAR-SPLITTING-2D-5.b-/blob/main/docs/plots/images/Schema_pointInPolygon.png?raw=true" alt="Lavoro di pointInPolygonClassification"/> </p><h2 id="Esempio-dello-splitting"><a class="docs-heading-anchor" href="#Esempio-dello-splitting">Esempio dello splitting</a><a id="Esempio-dello-splitting-1"></a><a class="docs-heading-anchor-permalink" href="#Esempio-dello-splitting" title="Permalink"></a></h2><p>Riportiamo un esempio di splitting effettuato durante lo studio definitivo del progetto attraverso due screenshot fondamentali:</p><p><img src="https://github.com/MarcoCap13/LAR-SPLITTING-2D-5.b-/blob/main/examples/2d/image/splitting_figura1.png?raw=true=150x" alt="Lavoro di splitting (1)"/> <img src="https://github.com/MarcoCap13/LAR-SPLITTING-2D-5.b-/blob/main/examples/2d/image/splitting_figura2.png?raw=true=150x" alt="Lavoro di splitting (2)"/></p><p>Nella <strong>prima figura</strong> (di sinistra) vediamo le intersezioni del bounding-box i-esimo con i restanti boundingbox e nella <strong>seconda figura</strong> vediamo la generazione dei punti dell&#39;intersezioni tra le varie parti.</p><h2 id="Funzioni-aggiuntive-create"><a class="docs-heading-anchor" href="#Funzioni-aggiuntive-create">Funzioni aggiuntive create</a><a id="Funzioni-aggiuntive-create-1"></a><a class="docs-heading-anchor-permalink" href="#Funzioni-aggiuntive-create" title="Permalink"></a></h2><p>In questa sezione verranno illustrate tutte le funzioni secondarie da noi utilizzate create per migliorare, alleggerire e semplificare gran parte del codice.</p><ul><li><p><strong>addIntersection</strong>(covers::Array{Array{Int64,1},1}, i::Int64, iterator) aggiunge gli elementi di iterator nell&#39;i-esimo array di covers.</p></li><li><p><strong>createIntervalTree</strong>(boxdict::AbstractDict{Array{Float64,1},Array{Int64,1}}) dato un insieme ordinato, crea un intervalTree; Nel particolare parliamo di una struttura dati che contiene intervalli e che ci consente di cercare e trovare in maniera efficiente tutti gli intervalli che si sovrappongono ad un determinato intervallo o punto.</p></li><li><p><strong>removeIntersection</strong>(covers::Array{Array{Int64,1},1}):</p></li></ul><p>siamo riusciti a rendere più stabile il tutto diminuendo in linea generale i tempi di calcolo della funzione stessa.  Quest&#39;ultima elimina le intersezioni di ogni boundingbox con loro stessi.</p><h2 id="Test-delle-funzioni-principali-e-aggiuntive"><a class="docs-heading-anchor" href="#Test-delle-funzioni-principali-e-aggiuntive">Test delle funzioni principali e aggiuntive</a><a id="Test-delle-funzioni-principali-e-aggiuntive-1"></a><a class="docs-heading-anchor-permalink" href="#Test-delle-funzioni-principali-e-aggiuntive" title="Permalink"></a></h2><p>inizialmente si sono eseguiti i test pre-esistenti per verificare il corretto funzionamento delle funzioni principali anche dopo aver effettuato lo studio di parallelizzazione con le macro dei singoli task. Dopo aver verificato il successo di questi, si è proceduto alla realizzazione di nuovi test:</p><ol><li><p><strong>@testset &quot;createIntervalTree test&quot;</strong>: creato un <em>OrderedDict</em> e un <em>intervaltrees</em> vogliamo testare che i dati siano stati disposti nel giusto ordine nella struttura dati. Per farlo estraiamo i singoli valori e li confrontiamo con i valori che ci aspettiamo di trovare nelle singole locazioni.</p></li><li><p><strong>@testset &quot;removeIntersection test&quot;</strong>: avendo isolato il task della funzione spaceindex che rimuove le intersezioni dei singoli boundingbox con se stesso, vogliamo assicurarci che funzioni nel modo corretto. Per farlo creiamo un array covers di test e controlliamo che la funzione modifichi la struttura dati nel modo corretto per ogni valore.</p></li><li><p><strong>@testset &quot;addIntersection test&quot;</strong>: avendo isolato il task della funzione <em>boxcovering</em> che aggiunge in &#39;covers&#39; in i-esima posizione tutti i bounding box che intersecano l&#39;i-esimo bounding box, vogliamo assicurarci che funzioni nel modo corretto. Per farlo creiamo un boundingbox di test e un OrderedDict con cui creare un <em>intervalTree</em>. A questo punto diamo queste variabili come input alla nostra funzione e confrontiamo il risultato ottenuto con quello atteso.</p></li></ol><p>Per quanto rigurdano i test delle funzioni principali da noi studiate, abbiamo svolto con successo i test sulle funzioni iniziali ricevendo i risultati aspettati. Solo successivamente (con un po&#39; di difficoltà) abbiamo svolto i test sulle funzioni da noi modificate arrivando alla completa correttezza di quest&#39;ultimi. nello specifico si possono revisionare i vari test nei vari <em>notebook</em>  aggiornati, seguendo il link qui riportato: \newline https://github.com/MarcoCap13/LAR-SPLITTING-2D-5.b-/tree/main/notebook</p><h2 id="Considerazioni-finali-sulla-parallelizzazione"><a class="docs-heading-anchor" href="#Considerazioni-finali-sulla-parallelizzazione">Considerazioni finali sulla parallelizzazione</a><a id="Considerazioni-finali-sulla-parallelizzazione-1"></a><a class="docs-heading-anchor-permalink" href="#Considerazioni-finali-sulla-parallelizzazione" title="Permalink"></a></h2><p>Durante lo studio preliminare ed esecutivo, abbiamo cercato di ottimizzare il nostro codice sia a livello di CPU che GPU. Considerato questo, abbiamo deciso di concentrarci maggiormente sulla parallelizzazione su CPU poichè uno dei pc utilizzati per il progetto era sprovvisto di una GPU dedicata. Per la parallelizzazione su CPU abbiamo utilizzato maggiormente le macro sopra elencate: <em>@threads</em> e <em>@spawn</em>. La prima viene usata su un <em>ciclo for</em> per dividere lo spazio di iterazione su più thread secondo una certa politica di scheduling, mentre la seconda permette di eseguire una funzione su un thread libero nel momento dell&#39;esecuzione. <strong>@threads</strong> viene usata nella funzione removeIntersection(), boxcovering() e infine in addIntersection(), mentre <strong>@spawn</strong> viene usata principalmente nella funzione spaceindex(). Per eseguire questo tipo di parallelizzazione bisogna tenere conto del numero di core presenti sulla macchina e proprio per questo motivo abbiamo provato a lavorare con la <strong>workstation DGX-1</strong> di <em>nvidia</em>  per poter raggiungere prestazioni migliori. Anche con ciò, si è notato che utilizzare un numero di thread maggiore di quelli disponibili non porta ad un aumento delle prestazioni. Il numero di thread da assegnare ai vari processi julia va stabilito prima dell&#39;avvio e può essere controllato e settato tramite la funzione <em>nthreads()</em>. Successivamente abbiamo testato le prestazioni di <em>spaceindex</em> e <em>pointInPolygon</em>,le funzioni più importanti per lo <em>splitting</em>. Nello specifico abbiamo visto cosa accadeva al variare del numero di thread, in particolare, quando si hanno a disposizione uno, quattro o otto thread (il massimo ottenibile dalla worksation DGX). Analizzando i tempi, si evince che il numero di thread deve essere scelto in base alla complessità del modello preso in esame. Infatti, utilizzando modelli semplici, un numero elevato di thread porta ad un peggioramento delle prestazioni, mentre all&#39;aumentare della complessità si ha un miglioramento.</p><h2 id="Grafo-delle-dipendenze-aggiornato"><a class="docs-heading-anchor" href="#Grafo-delle-dipendenze-aggiornato">Grafo delle dipendenze aggiornato</a><a id="Grafo-delle-dipendenze-aggiornato-1"></a><a class="docs-heading-anchor-permalink" href="#Grafo-delle-dipendenze-aggiornato" title="Permalink"></a></h2><p>In sintesi, questo <strong>grafo</strong> rappresenta il lavoro svolto sino ad ora con tutte le nuove funzioni create, aggiornate ed aggiunte. I nodi color celeste sono le funzioni di supporto, i nodi colorati di rosso sono le funzioni principali della classe e gli ultimi colorati di blu sono funzioni secondarie equamente importanti alla fine del progetto stesso. Nello specifico il nodo <em>Utility</em>function<em>PointInPolygon</em>1-15_  racchiude tutte le 15 funzioni create per il supporto a PointInPolygonclassification.</p><p><img src="https://github.com/MarcoCap13/LAR-SPLITTING-2D-5.b-/blob/main/docs/plots/images/grafoRefactoring_V2.png?raw=true" alt="Grafo delle dipendenze della classe Refactoring (Aggiornato)"/></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="relazione_esecutiva.html">« Studio Esecutivo</a><a class="docs-footer-nextpage" href="docs2d.html">Docstring »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 4 July 2022 22:10">Monday 4 July 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
